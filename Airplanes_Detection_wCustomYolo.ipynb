{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohK1-MWcx7Y9",
        "outputId": "3a28606a-f1d4-4f8f-8655-6795b09487e3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "8ZalkEeGx9fm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k6Tg-b-FxzR3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class AirplanesDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, num_samples=None, transform=None):\n",
        "        self.list_of_images = pd.read_csv(csv_file)\n",
        "        self.images_directory = img_dir\n",
        "        if num_samples is not None:\n",
        "            self.list_of_images = self.list_of_images.head(num_samples)\n",
        "        self.transform = transform if transform is not None else transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.list_of_images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.images_directory, self.list_of_images.iloc[idx, 0])\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "\n",
        "        bbox = np.array(self.list_of_images.iloc[idx, 1:5].values, dtype=np.float32)\n",
        "\n",
        "        center_x = (bbox[0] + bbox[2]) / 2\n",
        "        center_y = (bbox[1] + bbox[3]) / 2\n",
        "        width = bbox[2] - bbox[0]\n",
        "        height = bbox[3] - bbox[1]\n",
        "\n",
        "        center_x /= 224\n",
        "        center_y /= 224\n",
        "        width /= 224\n",
        "        height /= 224\n",
        "        bbox = torch.tensor([center_x, center_y, width, height], dtype=torch.float32)\n",
        "\n",
        "        return image, bbox.unsqueeze(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "dataset_path = '/content/drive/MyDrive/Colab Notebooks/dl/airplanes-dataset'\n",
        "\n",
        "csv_file_path = os.path.join(dataset_path, 'airplanes.csv')\n",
        "image_directory = os.path.join(dataset_path, 'images')\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = AirplanesDataset(csv_file=csv_file_path, img_dir=image_directory, num_samples=100, transform=transformations)\n",
        "\n",
        "image, target = dataset[0]\n",
        "print(image.shape, target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErrAO9TyyLnd",
        "outputId": "ab0b6261-3753-4a5d-d176-2522e1bd2c14"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 224, 224]) tensor([[0.8951, 0.4196, 1.2634, 0.5268]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "dataset_size = len(dataset)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = int(0.15 * dataset_size)\n",
        "test_size = dataset_size - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "print(f\"Dataset size: {dataset_size}\")\n",
        "print(f\"Train size: {len(train_dataset)}\")\n",
        "print(f\"Validation size: {len(val_dataset)}\")\n",
        "print(f\"Test size: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3YJ6St7yjTF",
        "outputId": "28814a66-8a4e-448c-95b1-95c226578e6e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset size: 100\n",
            "Train size: 80\n",
            "Validation size: 15\n",
            "Test size: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 10\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "S89wdapQyl-C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleYOLO(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleYOLO, self).__init__()\n",
        "        # Backbone: Extracción de características\n",
        "        self.backbone = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.final_layer = nn.Conv2d(128, 5, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.final_layer(x)\n",
        "        x = nn.functional.adaptive_avg_pool2d(x, 1)\n",
        "        x = x.view(x.size(0), 5)\n",
        "        return x[:, :4]  # Retorna solo las coordenadas del bounding box\n"
      ],
      "metadata": {
        "id": "KxRqN0jW0YAX"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo\n",
        "model = SimpleYOLO()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAmJW3iD0ePA",
        "outputId": "c30bb4c3-f7a8-436a-ea59-682abd588772"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleYOLO(\n",
            "  (backbone): Sequential(\n",
            "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (4): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): ReLU()\n",
            "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (12): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (13): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (14): ReLU()\n",
            "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (final_layer): Conv2d(128, 5, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "from torchvision.ops import generalized_box_iou_loss\n",
        "\n",
        "def fit(model, train_loader, val_loader, epochs, optimizer, checkpoint_path):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device).squeeze(1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            outputs = outputs.squeeze()  # Asegura que outputs sea [batch_size, 4]\n",
        "\n",
        "            loss = generalized_box_iou_loss(outputs, targets)\n",
        "            loss = loss.mean()\n",
        "\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f'Epoch {epoch + 1}, Batch {i + 1}/{len(train_loader)}, Train Loss: {loss.item():.4f}')\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "        print(f'Epoch {epoch + 1}, Average Training Loss: {avg_train_loss:.4f}, Time: {time.time() - start_time:.2f}s')\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device).squeeze(1)\n",
        "                outputs = model(inputs)\n",
        "                outputs = outputs.squeeze()\n",
        "\n",
        "                batch_loss = generalized_box_iou_loss(outputs, targets)\n",
        "                batch_loss = batch_loss.mean()\n",
        "                val_loss += batch_loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        print(f'Epoch {epoch + 1}, Average Validation Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f'New best model saved with avg_val_loss: {best_val_loss:.4f}')\n",
        "\n",
        "    return avg_train_loss, avg_val_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "r4B_asuV2grS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "# Inicializa el modelo\n",
        "model = SimpleYOLO()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "epochs = 50\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "checkpoint_path = \"/content/drive/MyDrive/Colab Notebooks/dl/airplanes_model/airplanes-yolo-model\"\n",
        "\n",
        "# Llama al método de entrenamiento\n",
        "train_loss, val_loss = fit(model, train_loader, val_loader, epochs, optimizer, checkpoint_path)\n",
        "\n",
        "print(f\"Training Loss: {train_loss}\")\n",
        "print(f\"Validation Loss: {val_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cE26bebZ2iU3",
        "outputId": "ba834134-c5b1-4164-e78a-0d6d3b02edc8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Training Loss: -3.0665, Time: 14.39s\n",
            "Epoch 1, Average Validation Loss: 1.9647\n",
            "New best model saved with avg_val_loss: 1.9647\n",
            "Epoch 2, Average Training Loss: -102.5345, Time: 0.61s\n",
            "Epoch 2, Average Validation Loss: 1.4327\n",
            "New best model saved with avg_val_loss: 1.4327\n",
            "Epoch 3, Average Training Loss: -824589.2492, Time: 0.69s\n",
            "Epoch 3, Average Validation Loss: -0.0951\n",
            "New best model saved with avg_val_loss: -0.0951\n",
            "Epoch 4, Average Training Loss: -1939362.4494, Time: 0.69s\n",
            "Epoch 4, Average Validation Loss: 1.6253\n",
            "Epoch 5, Average Training Loss: -3290936.8386, Time: 0.70s\n",
            "Epoch 5, Average Validation Loss: 546.7478\n",
            "Epoch 6, Average Training Loss: -8280372.6579, Time: 0.69s\n",
            "Epoch 6, Average Validation Loss: 2046.1840\n",
            "Epoch 7, Average Training Loss: -5460369.2971, Time: 0.60s\n",
            "Epoch 7, Average Validation Loss: 2103.4165\n",
            "Epoch 8, Average Training Loss: -9890201.5759, Time: 0.59s\n",
            "Epoch 8, Average Validation Loss: 956.2035\n",
            "Epoch 9, Average Training Loss: -9914967.3488, Time: 0.60s\n",
            "Epoch 9, Average Validation Loss: 1002.5437\n",
            "Epoch 10, Average Training Loss: -28131348.9081, Time: 0.60s\n",
            "Epoch 10, Average Validation Loss: 4616.4526\n",
            "Epoch 11, Average Training Loss: -21894282.7509, Time: 0.59s\n",
            "Epoch 11, Average Validation Loss: 5689.0072\n",
            "Epoch 12, Average Training Loss: -39578109.8579, Time: 0.60s\n",
            "Epoch 12, Average Validation Loss: 2088.5915\n",
            "Epoch 13, Average Training Loss: -58773566.9018, Time: 0.60s\n",
            "Epoch 13, Average Validation Loss: 2480.0198\n",
            "Epoch 14, Average Training Loss: -91920301.1245, Time: 0.59s\n",
            "Epoch 14, Average Validation Loss: 2218.4158\n",
            "Epoch 15, Average Training Loss: -96879051.0047, Time: 0.61s\n",
            "Epoch 15, Average Validation Loss: 7371.9045\n",
            "Epoch 16, Average Training Loss: -113348838.1829, Time: 0.57s\n",
            "Epoch 16, Average Validation Loss: 446.1545\n",
            "Epoch 17, Average Training Loss: -126685129.0524, Time: 0.59s\n",
            "Epoch 17, Average Validation Loss: -206.2087\n",
            "New best model saved with avg_val_loss: -206.2087\n",
            "Epoch 18, Average Training Loss: -186408776.1519, Time: 0.60s\n",
            "Epoch 18, Average Validation Loss: 603.5332\n",
            "Epoch 19, Average Training Loss: -153501246.8467, Time: 0.59s\n",
            "Epoch 19, Average Validation Loss: 9926.1265\n",
            "Epoch 20, Average Training Loss: -270275716.3880, Time: 0.61s\n",
            "Epoch 20, Average Validation Loss: 6462.8794\n",
            "Epoch 21, Average Training Loss: -299663181.0072, Time: 0.67s\n",
            "Epoch 21, Average Validation Loss: 5011.7939\n",
            "Epoch 22, Average Training Loss: -428683370.7872, Time: 0.68s\n",
            "Epoch 22, Average Validation Loss: 26520.2441\n",
            "Epoch 23, Average Training Loss: -435649912.0695, Time: 0.67s\n",
            "Epoch 23, Average Validation Loss: 23548.4658\n",
            "Epoch 24, Average Training Loss: -626961526.4268, Time: 0.76s\n",
            "Epoch 24, Average Validation Loss: 3453.5635\n",
            "Epoch 25, Average Training Loss: -684517613.9592, Time: 0.57s\n",
            "Epoch 25, Average Validation Loss: 245.1221\n",
            "Epoch 26, Average Training Loss: -1045170734.3491, Time: 0.61s\n",
            "Epoch 26, Average Validation Loss: 1762.6040\n",
            "Epoch 27, Average Training Loss: -715985001.7963, Time: 0.60s\n",
            "Epoch 27, Average Validation Loss: 14642.0244\n",
            "Epoch 28, Average Training Loss: -732164634.8427, Time: 0.59s\n",
            "Epoch 28, Average Validation Loss: 2576.3241\n",
            "Epoch 29, Average Training Loss: -1020229194.7707, Time: 0.60s\n",
            "Epoch 29, Average Validation Loss: 994.4980\n",
            "Epoch 30, Average Training Loss: -1599515051.0393, Time: 0.62s\n",
            "Epoch 30, Average Validation Loss: 20649.5645\n",
            "Epoch 31, Average Training Loss: -1400141178.7081, Time: 0.60s\n",
            "Epoch 31, Average Validation Loss: 31004.1562\n",
            "Epoch 32, Average Training Loss: -1574155287.6174, Time: 0.59s\n",
            "Epoch 32, Average Validation Loss: 4153.8703\n",
            "Epoch 33, Average Training Loss: -838798656.6519, Time: 0.59s\n",
            "Epoch 33, Average Validation Loss: 12763.2310\n",
            "Epoch 34, Average Training Loss: -1717650748.0867, Time: 0.59s\n",
            "Epoch 34, Average Validation Loss: 19861.0820\n",
            "Epoch 35, Average Training Loss: -2338459736.0636, Time: 0.61s\n",
            "Epoch 35, Average Validation Loss: 6327.9189\n",
            "Epoch 36, Average Training Loss: -2710827437.6162, Time: 0.60s\n",
            "Epoch 36, Average Validation Loss: 41357.5664\n",
            "Epoch 37, Average Training Loss: -2544798725.1584, Time: 0.59s\n",
            "Epoch 37, Average Validation Loss: -5745.4681\n",
            "New best model saved with avg_val_loss: -5745.4681\n",
            "Epoch 38, Average Training Loss: -2467714998.2611, Time: 0.61s\n",
            "Epoch 38, Average Validation Loss: 201327.8789\n",
            "Epoch 39, Average Training Loss: -3128726955.8715, Time: 0.67s\n",
            "Epoch 39, Average Validation Loss: 6117.3984\n",
            "Epoch 40, Average Training Loss: -3387810480.7466, Time: 0.67s\n",
            "Epoch 40, Average Validation Loss: 36478.5078\n",
            "Epoch 41, Average Training Loss: -2809637454.4702, Time: 0.68s\n",
            "Epoch 41, Average Validation Loss: 3785.8398\n",
            "Epoch 42, Average Training Loss: -4469677525.2678, Time: 0.70s\n",
            "Epoch 42, Average Validation Loss: 53753.5234\n",
            "Epoch 43, Average Training Loss: -4313810952.3232, Time: 0.62s\n",
            "Epoch 43, Average Validation Loss: 33428.4033\n",
            "Epoch 44, Average Training Loss: -4585343084.1479, Time: 0.60s\n",
            "Epoch 44, Average Validation Loss: 111904.1055\n",
            "Epoch 45, Average Training Loss: -4751301352.4692, Time: 0.60s\n",
            "Epoch 45, Average Validation Loss: 15851.3320\n",
            "Epoch 46, Average Training Loss: -5581642741.3027, Time: 0.58s\n",
            "Epoch 46, Average Validation Loss: 5906.2305\n",
            "Epoch 47, Average Training Loss: -6435411942.2852, Time: 0.60s\n",
            "Epoch 47, Average Validation Loss: -836.2048\n",
            "Epoch 48, Average Training Loss: -7023861840.0523, Time: 0.60s\n",
            "Epoch 48, Average Validation Loss: 7140.2803\n",
            "Epoch 49, Average Training Loss: -7413565659.1454, Time: 0.59s\n",
            "Epoch 49, Average Validation Loss: 556138.5781\n",
            "Epoch 50, Average Training Loss: -3198696904.2850, Time: 0.60s\n",
            "Epoch 50, Average Validation Loss: 102244.4102\n",
            "Training Loss: -3198696904.284973\n",
            "Validation Loss: 102244.41015625\n"
          ]
        }
      ]
    }
  ]
}